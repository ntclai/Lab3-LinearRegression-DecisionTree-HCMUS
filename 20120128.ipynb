{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dw29NSYmFpyS"
   },
   "source": [
    "# Lab03: Linear Regression and Decision Tree.\n",
    "\n",
    "- Student ID: 20120128\n",
    "- Student name: Nguyễn Thị Cẩm Lai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHR1Zj5GFpyT"
   },
   "source": [
    "**How to do your homework**\n",
    "\n",
    "\n",
    "You will work directly on this notebook; the word `TODO` indicate the parts you need to do.\n",
    "\n",
    "You can discuss ideas with classmates as well as finding information from the internet, book, etc...; but *this homework must be your*.\n",
    "\n",
    "**How to submit your homework**\n",
    "\n",
    "Before submitting, rerun the notebook (`Kernel` ->` Restart & Run All`).\n",
    "\n",
    "Rename your notebook with `ID.ipynb` (for example, if your ID is 1234567, rename your notebook with `1234567.ipynb`) and submit it on moodle.\n",
    "\n",
    "**Contents:**\n",
    "\n",
    "- Linear Regression.\n",
    "- Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFOYpg2nDxqE"
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REHkv-y8FpyU"
   },
   "source": [
    "### 1. The hypothesis set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e75OMY0KFpyU"
   },
   "source": [
    "- Linear regression is a **linear** model, e.g. a model that assumes a linear relationship between the input variables (x) and the single output variable (y). More specifically, that y can be calculated from a linear combination of the input variables (x).\n",
    "- Generally, a linear model will make predictions by calculating a weighted sum of the input features (independent variables). \n",
    "$$ \\hat{y}=w_0+w_1x_1+w_2x_2+...+w_nx_n $$\n",
    "    - $\\hat{y}$ is the predicted value.\n",
    "    - $n$ is the number of features.\n",
    "    - $x_i$ is the $i^{th}$ feature value.\n",
    "    - $w_j$ is the $j^{th}$ model parameter (including the bias term $w_0$ and the feature weights $w_1,w_2,...w_n)$.\n",
    "$$\\hat{y}=h_{\\mathbf{w}}\\left(\\mathbf{x}\\right)=\\mathbf{w}^{T}\\cdot\\mathbf{x}$$\n",
    "    - $\\mathbf{w}$ is the model **parameter vector** (including the bias term $w_0$ and the feature weights $w_1,w_2,...w_n$).\n",
    "    - $\\mathbf{w}^T$ is a transpose  of $\\mathbf{w}$ (a row vector insteade of column vector).\n",
    "    - $\\mathbf{x}$ is the instance's **feature vector**, *containing* $x_0$ to $x_n$, with $x_0$ *always equal to* 1.\n",
    "    - $\\mathbf{w}^{T}\\cdot\\mathbf{x}$ is the dot product of $\\mathbf{w}^T$ and $\\mathbf{x}$.\n",
    "    - $h_{\\mathbf{w}}$ is the hypothesis function, using the parameters $\\mathbf{w}$.\n",
    "![Bias](Bias.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5l8F4lnjFpyV"
   },
   "source": [
    "### 2. Performance measure and the learning goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdJNZ2q6FpyX"
   },
   "source": [
    "- Before we start to train the model, we need to determine how good the model fits the training data. There are a couple of ways to determine the level of quality, but we are going to use the most popular one and that is the **MSE** (Mean Square Error). We need to find the value for $\\mathbf{w}$ that will minimize the MSE:\n",
    "$$\\mathbf{w}=\\arg\\min MSE_{\\mathcal{D}_{train}}$$\n",
    "\n",
    "\n",
    "- MSE on the train set $\\mathcal{D}_{train}$ denoted as $\\left(\\mathbf{X},\\mathbf{y}\\right)$ including m samples $\\left\\{\\left(\\mathbf{x}_1,y_1\\right),\\left(\\mathbf{x}_2,y_2\\right),...\\left(\\mathbf{x}_m,y_m\\right)\\right\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTOZj7HfFpyY"
   },
   "source": [
    "$$MSE\\left(X,h_{\\mathbf{w}}\\right)=\\dfrac{1}{m}\\sum_{i=1}^{m}\\left(\\mathbf{w}^T\\cdot\\mathbf{x}_i - y_i\\right )^2$$\n",
    "$$MSE\\left(X,h_{\\mathbf{w}}\\right)=\\dfrac{1}{m}\\Vert\\mathbf{X}\\mathbf{w}-\\mathbf{y}\\Vert^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wXM1_zDDlcc"
   },
   "source": [
    "Example below is a plot of an MSE function where the true target value is 100, and the predicted values range between -10,000 to 10,000. The MSE loss (Y-axis) reaches its minimum value at prediction (X-axis) = 100. The range is 0 to ∞.\n",
    "![Plot of MSE Loss (Y-axis) vs. Predictions (X-axis)](MSE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORU-9tCxFpyZ"
   },
   "source": [
    "- To find the value of $\\mathbf{w}$ that minimizes the MSE cost function, the most common way (*we have known since high school*) is to solve the derivative (gradient) equation. \n",
    "$$\\mathbf{\\hat{w}}=\\left(\\mathbf{X}^T  \\mathbf{X}\\right)^{\\dagger}  \\mathbf{X}^T  \\mathbf{y}$$\n",
    "  - $\\mathbf{\\hat{w}}$ is the value of $\\mathbf{w}$ that minimizes the cost function\n",
    "  - **Notice that** $\\mathbf{X}^T  \\mathbf{X}$ is not always invertible. $\\left(\\mathbf{X}^T  \\mathbf{X}\\right)^{\\dagger}$ is pseudo-inverse of $\\left(\\mathbf{X}^T \\mathbf{X}\\right)$ - a general case of inverse when the matrix is not invertible or not even square."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Tgy-tRYFpyZ"
   },
   "source": [
    "### 3. Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qauCdk7LFpya"
   },
   "source": [
    "#### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "70Mis-p9Fpyd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn.datasets as datasets\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRr06hARFpyk"
   },
   "source": [
    "#### Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "g0K3G_SOFpyk"
   },
   "outputs": [],
   "source": [
    "X,y=datasets.make_regression(n_samples=100,n_features=1, noise=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBFWzeY3Fpyp"
   },
   "source": [
    "#### Load and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4BpxLtG3Fpyq"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize data \n",
    "\n",
    "plt.plot(X, y, 'ro')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLDAEVR8Fpyx"
   },
   "source": [
    "**TODO:** \n",
    "\n",
    "- Your observation about data:\n",
    "    - Theo hàm khởi tạo dữ liệu, thì bộ dữ liệu này có 100 mẫu với độ lệch chuẩn của độ nhiễu gaussian thấp áp dụng cho đầu ra (y) là 5.\n",
    "    - Biến độc lập x và biến phụ thuộc y của bộ dữ liệu có mối quan hệ tuyến tính cao.\n",
    "    - Các điểm dữ liệu trên đồ thị có độ phân tán thấp, phân bố theo hình dạng tuyến tính."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrb7peM1Fpyz"
   },
   "source": [
    "#### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DdPXTgoAFpyz"
   },
   "outputs": [],
   "source": [
    "def train_linear_regression(X, y):\n",
    "    '''\n",
    "    Trains Linear Regression on the dataset (X, y).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array, shape (m, d + 1)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); \n",
    "        the first column of this matrix is all ones (corresponding to x_0).\n",
    "    y : numpy array, shape (m, 1)\n",
    "        The vector of outputs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    w : numpy array, shape (d + 1, 1)\n",
    "        The vector of parameters of Linear Regression after training.\n",
    "    '''\n",
    "    # TODO\n",
    "    #Thực hiện công thức tính w được cho ở lý thuyết bên trên\n",
    "    #T: ký hiệu ma trận chuyển vị\n",
    "    #_inv: ký hiệu ma trận khả nghịch\n",
    "    XTX=X.T.dot(X)\n",
    "    XTX_inv=np.linalg.inv(XTX) #Lấy khả nghịch của ma trận XTX\n",
    "    \n",
    "    w=XTX_inv.dot(X.T).dot(y)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wDgQ-5EDFpy5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_added_X.shape = (100, 2)\n",
      "y.shape = (100,)\n"
     ]
    }
   ],
   "source": [
    "# Construct one_added_X \n",
    "# TODO:\n",
    "# First column of one_added_X is all ones (corresponding to x_0).\n",
    "ones = np.ones(X.shape[0])\n",
    "one_added_X=np.column_stack([ones, X])\n",
    "print ('one_added_X.shape =', one_added_X.shape)\n",
    "print ('y.shape =', y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVhd2dvCFpzE"
   },
   "source": [
    "#### Train our model and visualize result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "y3YvmkEEFpzE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.8433462685196784, 2.075879348938872)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = train_linear_regression(one_added_X, y)\n",
    "\n",
    "# Visualize result\n",
    "predicted_ys = one_added_X.dot(w)\n",
    "\n",
    "plt.plot(X,y,'ro')\n",
    "\n",
    "x_min, x_max = plt.xlim()\n",
    "xs = np.array([x_min, x_max]).reshape(-1, 1)\n",
    "\n",
    "# Construct one_added_xs \n",
    "# TODO:\n",
    "# First column of one_added_xs is all ones (corresponding to x_0).\n",
    "ones = np.ones(xs.shape[0])\n",
    "ones_added_xs=np.column_stack([ones, xs])\n",
    "\n",
    "predicted_ys = ones_added_xs.dot(w)\n",
    "plt.plot(xs, predicted_ys)\n",
    "plt.xlim(x_min, x_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTO6ilruFpzH"
   },
   "source": [
    "- **TODO**: Discuss about advantages and disadvantages of `Linear Regression`:\n",
    "\n",
    "| Advantages | Disadvantages |\n",
    "| :- | -: |\n",
    "| Về mặt lí thuyết các mô hình hồi quy tuyến tính dễ hiểu hơn những loại mô hình khác vì chúng được xây dựng dựa trên các nguyên tắc thống kê cơ bản: hệ số tương quan giữa các biến, lỗi bình phương trung bình,...|Mô hình hoạt động hiệu quả với các bộ dữ liệu chứa các giá trị số (numeric) chứ không phù hợp với các bộ dữ liệu chứa các biến phân loại (categorical)|\n",
    "| Mô hình đơn giản dễ cài đặt và giải thích. Việc đào tạo mô hình dễ đạt hiệu quả cao nhờ việc tinh chỉnh các siêu tham số | Không hoạt động tốt nếu dữ liệu chứa các điểm ngoại lệ (outliers), dữ liệu phân bố lộn xộn, phi tuyến tính. Khi đó hồi quy tuyến tính cố gắng tìm ra đường thẳng phù hợp nhất với bộ dữ liệu, dễ dẫn đến hiện tượng underfitting |\n",
    "| Hiệu quả đào tạo cao trên dữ liệu có biến độc lập và biến phụ thuộc có mối quan hệ tuyến tính | Có nhiều cách tránh tình trạng overfitting nhưng trong hồi quy tuyến tính đa biến lại rất dễ rơi vào tình trạng overfitting|\n",
    "| Có nhiều phương pháp để tránh được tình trạng overfitting: regularization, cross validation,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocxeCj9kEIHX"
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0woNUwnsEYLG"
   },
   "source": [
    "### 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "szAMv4OMD7hY"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPi8pVmYEffr"
   },
   "source": [
    "### 2. Load Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4k11PMVJEbaB"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "iris=datasets.load_iris()\n",
    "\n",
    "X=iris.data\n",
    "y=iris.target\n",
    "\n",
    "#split dataset into training data and testing data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQkTy3NdEi6F"
   },
   "source": [
    "### 3. Decision Tree: Iterative Dichotomiser 3 (ID3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-Lew9FgEsER"
   },
   "source": [
    "#### 3.1 Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8trBjGfkEv8l"
   },
   "source": [
    "Expected value of the self-information (entropy):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGuAljLcEyH9"
   },
   "source": [
    "$$Entropy=-\\sum_{i}^{n}p_ilog_{2}(p_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HL49SURpE1Qi"
   },
   "source": [
    "The entropy function gets the smallest value if there is a value of $p_i$ equal to 1, reaches the maximum value if all $ p_i $ are equal. These properties of the entropy function make it is an expression of the disorder, or randomness of a system, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "x4DF6EDjE06Y"
   },
   "outputs": [],
   "source": [
    "def entropy(counts, n_samples):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    counts: shape (n_classes): list number of samples in each class (list số lượng mẫu mỗi lớp)\n",
    "    n_samples: number of data samples (số lượng mẫu của bộ dữ liệu)\n",
    "    \n",
    "    -----------\n",
    "    return entropy \n",
    "    \"\"\"\n",
    "\n",
    "    #TODO\n",
    "    entropy=0.0\n",
    "    for i in counts:\n",
    "        pi=float(i/n_samples)\n",
    "        entropy=entropy-pi*np.log2(pi)\n",
    "    \n",
    "    return entropy\n",
    "    \n",
    "    \"\"\"\n",
    "    #TODO\n",
    "    temp=[-(i/n_samples)*np.log2(i/n_samples) for i in counts]\n",
    "    temp=np.array(temp)\n",
    "    return temp.sum()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "c8sW9chQEnbb"
   },
   "outputs": [],
   "source": [
    "def entropy_of_one_division(division): \n",
    "    \"\"\"\n",
    "    Returns entropy of a divided group of data\n",
    "    Data may have multiple classes\n",
    "    \"\"\"\n",
    "    n_samples = len(division)\n",
    "    n_classes = set(division)\n",
    "    \n",
    "    counts=[]\n",
    "    #count samples in each class then store it to list counts\n",
    "    #TODO:\n",
    "    for i in n_classes:\n",
    "        count=0\n",
    "        for j in division:\n",
    "            if i==j:\n",
    "                count+=1\n",
    "        counts.append(count)\n",
    "    return entropy(counts,n_samples),n_samples\n",
    "\n",
    "def get_entropy(y_predict, y):\n",
    "    \"\"\"\n",
    "    Returns entropy of a split\n",
    "    y_predict is the split decision by cutoff, True/Fasle\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    entropy_true, n_true = entropy_of_one_division(y[y_predict]) # left hand side entropy\n",
    "    entropy_false, n_false = entropy_of_one_division(y[~y_predict]) # right hand side entropy\n",
    "    # overall entropy\n",
    "    #TODO s=?\n",
    "    s=float(n_true/n)*entropy_true+float(n_false/n)*entropy_false\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGY4epqQFDb9"
   },
   "source": [
    "The information gain of classifying information set D by attribute A:\n",
    "$$ Gain(A)=Entrophy(D)-Entrophy_{A}(D)$$\n",
    "\n",
    "At each node in ID3, an attribute is chosen if its information gain is highest compare to others.\n",
    "\n",
    "All attributes of the Iris set are represented by continuous values. Therefore we need to represent them with discrete values. The simple way is to use a `cutoff` threshold to separate values of the data on each attribute into two part:` <cutoff` and `> = cutoff`.\n",
    "\n",
    "To find the best `cutoff` for an attribute, we replace` cutoff` with its values then compute the entropy, best `cutoff` achieved when value of entropy is smallest  $ \\left (\\arg \\min Entrophy_ {A} (D) \\right) $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXfxtxmqFGqr"
   },
   "source": [
    "#### 3.2 Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jneJVFZhFDtl"
   },
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, tree=None, depth=0):\n",
    "        '''Parameters:\n",
    "        -----------------\n",
    "        tree: decision tree\n",
    "        depth: depth of decision tree after training'''\n",
    "        \n",
    "        self.depth = depth\n",
    "        self.tree=tree\n",
    "    def fit(self, X, y, node={}, depth=0):\n",
    "        '''Parameter:\n",
    "        -----------------\n",
    "        X: training data\n",
    "        y: label of training data\n",
    "        ------------------\n",
    "        return: node \n",
    "        \n",
    "        node: each node represented by cutoff value and column index, value and children.\n",
    "         - cutoff value is thresold where you divide your attribute\n",
    "         - column index is your data attribute index\n",
    "         - value of node is mean value of label indexes, \n",
    "           if a node is leaf all data samples will have same label\n",
    "        \n",
    "        Note that: we divide each attribute into 2 part => each node will have 2 children: left, right.\n",
    "        '''\n",
    "        \n",
    "        #Stop conditions\n",
    "        \n",
    "        #if all value of y are the same \n",
    "        if np.all(y==y[0]):\n",
    "            return {'val':y[0]}\n",
    "\n",
    "        else: \n",
    "            col_idx, cutoff, entropy = self.find_best_split_of_all(X, y)    # find one split given an information gain \n",
    "            y_left = y[X[:, col_idx] < cutoff]\n",
    "            y_right = y[X[:, col_idx] >= cutoff]\n",
    "            node = {'index_col':col_idx,\n",
    "                        'cutoff':cutoff,\n",
    "                   'val':np.mean(y)}\n",
    "            node['left'] = self.fit(X[X[:, col_idx] < cutoff], y_left, {}, depth+1)\n",
    "            node['right'] = self.fit(X[X[:, col_idx] >= cutoff], y_right, {}, depth+1)\n",
    "            self.depth += 1 \n",
    "            self.tree = node\n",
    "            return node\n",
    "    \n",
    "    def find_best_split_of_all(self, X, y):\n",
    "        col_idx = None\n",
    "        min_entropy = 1\n",
    "        cutoff = None\n",
    "        for i, col_data in enumerate(X.T):\n",
    "            entropy, cur_cutoff = self.find_best_split(col_data, y)\n",
    "            if entropy == 0:                   #best entropy\n",
    "                return i, cur_cutoff, entropy\n",
    "            elif entropy <= min_entropy: #cập nhật min_entropy nếu nó là giá trị tôt\n",
    "                min_entropy = entropy\n",
    "                col_idx = i\n",
    "                cutoff = cur_cutoff\n",
    "               \n",
    "        return col_idx, cutoff, min_entropy\n",
    "    \n",
    "    def find_best_split(self, col_data, y):\n",
    "        ''' Parameters:\n",
    "        -------------\n",
    "        col_data: data samples in column'''\n",
    "         \n",
    "        min_entropy = 10\n",
    "\n",
    "        #Loop through col_data find cutoff where entropy is minimum\n",
    "        \n",
    "        for value in set(col_data):\n",
    "            y_predict = col_data < value\n",
    "            my_entropy = get_entropy(y_predict, y)\n",
    "            #TODO\n",
    "            #min entropy=?, cutoff=?\n",
    "            if my_entropy<=min_entropy:\n",
    "                min_entropy=my_entropy\n",
    "                cutoff=value\n",
    "            \n",
    "        return min_entropy, cutoff\n",
    "                                               \n",
    "    def predict(self, X):\n",
    "        tree = self.tree\n",
    "        pred = np.zeros(shape=len(X))\n",
    "        for i, c in enumerate(X):\n",
    "            pred[i] = self._predict(c)\n",
    "        return pred\n",
    "    \n",
    "    def _predict(self, row):\n",
    "        cur_layer = self.tree\n",
    "        while cur_layer.get('cutoff'):\n",
    "            if row[cur_layer['index_col']] < cur_layer['cutoff']:\n",
    "                cur_layer = cur_layer['left']\n",
    "            else:\n",
    "                cur_layer = cur_layer['right']\n",
    "        else:\n",
    "            return cur_layer.get('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGSI_4cjFLnI"
   },
   "source": [
    "#### 3.3 Classification on Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rJh76UyGFOFV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of your decision tree model on training data: 1.0\n",
      "Accuracy of your decision tree model: 0.96\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "tree = model.fit(X_train, y_train)\n",
    "pred=model.predict(X_train)\n",
    "print('Accuracy of your decision tree model on training data:', accuracy_score(y_train,pred))\n",
    "pred=model.predict(X_test)\n",
    "print('Accuracy of your decision tree model:', accuracy_score(y_test,pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vo-xgbEGFeZI"
   },
   "source": [
    "**TODO**: F1, Recall and Precision report\n",
    "\n",
    "### Giới thiệu\n",
    "Khi đã xây dựng một mô hình machine learning và huấn luyện nó trên một tập dữ liệu, điều tiếp theo chúng ta cần làm là đánh giá hiệu năng của mô hình trên tập dữ liệu mới.\n",
    "\n",
    "Khi thực hiện bài toán phân loại (classification), có 4 trường hợp của dự đoán có thể xảy ra:\n",
    "\n",
    "- **True Positive**: đối tượng ở lớp Positive, mô hình phân đối tượng vào lớp Positive (dự đoán đúng)\n",
    "- **True Negative**: đối tượng ở lớp Negative, mô hình phân đối tượng vào lớp Negative (dự đoán đúng)\n",
    "- **False Positive**: đối tượng ở lớp Negative, mô hình phân đối tượng vào lớp Positive (dự đoán sai)\n",
    "- **False Negative**: đối tượng ở lớp Positive, mô hình phân đối tượng vào lớp Negative (dự đoán sai)\n",
    "\n",
    "**Precision (độ chuẩn xác)**, **Recall (độ phủ)**, **F1** là các metric dùng để đánh giá hiệu quả của một mô hình học máy khi giải quyết các bài toán phân loại (classification), đặc biệt là các bài toán phân loại với các lớp có số lượng mẫu chênh lệch nhau nhiều. Mỗi metric sẽ có ý nghĩa và cách tính khác nhau.\n",
    "\n",
    "\n",
    "### Bài toán đặt ra\n",
    "\n",
    "Ở đây ta sẽ đưa ra một bài toán phân loại nhị phân để minh họa cho vai trò của các metric trên. Một bài toán đặt ra là: **Căn cứ vào các triệu chứng biểu hiện của một người, mô hình máy học phải xác định xem người đó có mắc covid 19 hay không?**\n",
    "\n",
    "**Quy ước nhãn:**\n",
    "- 1 (positive): dương tính với covid 19\n",
    "- 0 (negative): âm tính với covid 19\n",
    "\n",
    "**Quy ước các ký hiệu**:\n",
    "- TP (True Positive): Trường hợp dự đoán đúng mẫu dương tính.\n",
    "- FP (False Positive): Trường hợp dự đoán sai mẫu dương tính.\n",
    "- TN (True Negative): Trường hợp dự đoán đúng mẫu âm tính.\n",
    "- FN (False Negative): Trường hợp dự đoán sai mẫu âm tính.\n",
    "\n",
    "**Giả sử:**\n",
    "\n",
    "Ta có tổng số mẫu khảo sát là 1000 mẫu (tương ứng với 1000 người) trong đó chính xác có 900 mẫu âm tính và 100 mẫu là dương tính. Sau khi đưa qua mô hình phân loại kết quả mô hình cho ra như sau:\n",
    "\n",
    "![img](https://raw.githubusercontent.com/ntclai/EDA-World-Population/main/Untitled3.png)\n",
    "\n",
    "\n",
    "**Đánh giá:**\n",
    "\n",
    "$$Accuracy = \\frac{TP+TN}{TP + FP + TN + FN} = \\frac{40 + 880}{60 + 40 + 20 + 880} = 0.92 $$\n",
    "\n",
    "Mô hình này có thể dự đoán đúng đến 92% (có nghĩa là trong số 100 mẫu thì có 92 mẫu được phân loại chính xác). Đây có lẽ là độ chính xác cao, nhưng liệu nó có thật sự tốt hay không?\n",
    "\n",
    "Một vấn đề nghiêm trọng ta nhận thấy là số ca dương tính mà mô hình phát hiện chỉ chiếm 40% tổng số ca nhiễm mà trong bài toán này việc xác định đúng mẫu dương tính là vấn đề cực kỳ quan trọng vì nó liên quan đến sức khỏe cả cộng đồng. Do đó Accuracy tuy cao nhưng là vô nghĩa khi dùng để đánh giá cho mô hình có bộ dữ liệu bị hiện tượng mất cân bằng (các lớp có số lượng mẫu chênh lệch nhau nhiều) và mức quan trọng của các lớp là khác nhau.\n",
    "\n",
    "### Hướng giải quyết\n",
    "Các metric:  F1, Precision và Recall được sử dụng để khắc phục vấn đề trên. Bảng sau sẽ trình bày tóm tắt về các metric này:\n",
    "\n",
    "![img](https://raw.githubusercontent.com/ntclai/EDA-World-Population/main/Untitled4.png)\n",
    "\n",
    "### Nhận xét\n",
    "**Precision (Độ chuẩn xác)**: độ chuẩn xác càng cao thì mô hình sẽ dự đoán càng tốt cho các mẫu thuộc lớp positive.\n",
    "\n",
    "- Ví dụ: với Precision = 0,9 có nghĩa là mô hình dự đoán đúng 90 mẫu trong 100 mẫu mô hình dự đoán là positive.\n",
    "\n",
    "**Recall (Độ phủ)**: cho biết mức độ bỏ sót các mẫu thuộc lớp positive của mô hình. Recall càng cao chứng tỏ mô hình bỏ sót rất ít các mẫu thuộc lớp positive. Recall cũng có ý nghĩa gần tương tự như Precision, có cùng tử số nhưng có một chút khác biệt về mẫu số trong công thức tính toán.\n",
    "\n",
    "- Ví dụ: với Recall = 0,9 có nghĩa là mô hình dự đoán đúng 90 mẫu trong 100 mẫu thực sự là positive.\n",
    "\n",
    "**Trade off giữa Precision và Recall**: \n",
    "- Trong thực tế một mô hình phân loại nhị phân lý tưởng là khi có Precision và Recall cao (càng gần 1 càng tốt), tuy nhiên điều này là rất khó xảy ra. Thường sảy ra trường hợp Precision cao, Recall thấp hoặc Precision thấp, Recall cao. Khi đó rất khó để lựa chọn đâu là một mô hình tốt vì không biết rằng nên đánh giá theo Precision hay Recall. \n",
    "- Sự đánh đổi này thường xuyên diễn ra trong các bộ dữ liệu thực tế do đó cần tìm cách kết hợp cả Precision và Recall tạo ra một độ đo mới và đó chính là F1.\n",
    "\n",
    "**F1**: Xét thấy giá trị F1 được tính bằng cách sử dụng trung bình điều hòa, giá trị F1 luôn nằm trong khoảng của Precision và Recall. Do đó F1 sẽ phạt nặng hơn những trường hợp mô hình có Precision thấp, Recall cao hoặc Precision cao, Recall thấp. Đây là những trường hợp tương đương với dự báo thiên về một nhóm là positive hoặc negative nên không phải là mô hình tốt. Điểm số từ trung bình điều hòa sẽ giúp ta nhận biết được những trường hợp không tốt như vậy.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
